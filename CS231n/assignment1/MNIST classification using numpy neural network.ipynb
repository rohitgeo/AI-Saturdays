{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 70,000 images of 28x28=784 pixels each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.target[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  163 203  0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0  163 243 203  0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   82 254 253 203  0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0  203 253 252  81  0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0  132 253 224  81  0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0  253 252 102  0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0  163 254 172  0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   41 243 253  50  0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   52 253 254  50  0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0  173 252 233  30  0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   62 254 253  82  0   0   21  51  51 152  71  21  0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0  102 253 252 102 102 123 223 253 252 253 252 223  81  0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0  203 254 233 234 253 254 253 203 243 254 253 254 213  21  0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   41 243 253 151  51 151 151  70  0   40 151 151 253 252 102  0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   52 253 254  50  0   0   0   0   0   0   0   0  132 253 163  0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   51 252 253  50  0   0   0   0   0   0   0   0   92 252 162  0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   52 253 255 131  0   0   0   0   0   0   0   82 254 233  82  0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   31 232 253 252 183 102 102 102 102 142 203 243 253 151  0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0  123 255 253 254 253 254 253 254 253 254 253 142  20  0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   71 192 253 252 253 252 233 151 131  50  0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n",
      " 0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  \n"
     ]
    }
   ],
   "source": [
    "# visualize using some ascii art\n",
    "import random\n",
    "\n",
    "index = random.randint(0,len(mnist.data)-1) # visualize a random number from the MNIST data\n",
    "\n",
    "pixels = mnist.data[index].reshape((28, 28))\n",
    "\n",
    "for row in pixels:\n",
    "    [print('{:^4}'.format(pixel), end='') for pixel in row]\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b37368cf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = np.array(mnist.data[index], dtype='uint8')\n",
    "\n",
    "# Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "pixels = pixels.reshape((28, 28))\n",
    "\n",
    "# Plot\n",
    "plt.title('Label is {label}'.format(label=mnist.target[index]))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist.data = mnist.data/255.0*2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = mnist.data[:60000]\n",
    "y_train = mnist.target[:60000]\n",
    "\n",
    "x_test  = mnist.data[60000:]\n",
    "y_test  = mnist.target[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = x_train\n",
    "y = y_train.astype(np.uint8)\n",
    "\n",
    "Xt = x_test\n",
    "yt = y_test.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = unison_shuffled_copies(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two layer neural network in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss 2.322308\n",
      "iteration 100: loss 1.984647\n",
      "iteration 200: loss 1.431346\n",
      "iteration 300: loss 1.062887\n",
      "iteration 400: loss 0.690352\n",
      "iteration 500: loss 0.558953\n",
      "iteration 600: loss 0.535156\n",
      "iteration 700: loss 0.463688\n",
      "iteration 800: loss 0.447985\n",
      "iteration 900: loss 0.403202\n",
      "iteration 1000: loss 0.585579\n",
      "iteration 1100: loss 0.446848\n",
      "iteration 1200: loss 0.326479\n",
      "iteration 1300: loss 0.493121\n",
      "iteration 1400: loss 0.445217\n",
      "iteration 1500: loss 0.432230\n",
      "iteration 1600: loss 0.346519\n",
      "iteration 1700: loss 0.485739\n",
      "iteration 1800: loss 0.383756\n",
      "iteration 1900: loss 0.386374\n",
      "iteration 2000: loss 0.237091\n",
      "iteration 2100: loss 0.423637\n",
      "iteration 2200: loss 0.315242\n",
      "iteration 2300: loss 0.369491\n",
      "iteration 2400: loss 0.484731\n",
      "iteration 2500: loss 0.311369\n",
      "iteration 2600: loss 0.259375\n",
      "iteration 2700: loss 0.498405\n",
      "iteration 2800: loss 0.341113\n",
      "iteration 2900: loss 0.442184\n",
      "iteration 3000: loss 0.333467\n",
      "iteration 3100: loss 0.359184\n",
      "iteration 3200: loss 0.311288\n",
      "iteration 3300: loss 0.305589\n",
      "iteration 3400: loss 0.410398\n",
      "iteration 3500: loss 0.275164\n",
      "iteration 3600: loss 0.367684\n",
      "iteration 3700: loss 0.395425\n",
      "iteration 3800: loss 0.381667\n",
      "iteration 3900: loss 0.409154\n",
      "iteration 4000: loss 0.309926\n",
      "iteration 4100: loss 0.395536\n",
      "iteration 4200: loss 0.350483\n",
      "iteration 4300: loss 0.354743\n",
      "iteration 4400: loss 0.353875\n",
      "iteration 4500: loss 0.224368\n",
      "iteration 4600: loss 0.327699\n",
      "iteration 4700: loss 0.327069\n",
      "iteration 4800: loss 0.255297\n",
      "iteration 4900: loss 0.218054\n",
      "iteration 5000: loss 0.379810\n"
     ]
    }
   ],
   "source": [
    "h = 512 # size of hidden layer\n",
    "W = 0.01 * np.random.randn(X.shape[1],h)\n",
    "b = np.zeros((1,h))\n",
    "K = 10 # number of classes\n",
    "W2 = 0.01 * np.random.randn(h,K)\n",
    "b2 = np.zeros((1,K))\n",
    "# some hyperparameters\n",
    "step_size = 0.01 # 1e-0\n",
    "reg = 1e-3 # regularization strength\n",
    "\n",
    "batch_size=128\n",
    "\n",
    "# gradient descent loop\n",
    "num_examples = X.shape[0]\n",
    "for i in range(5100):\n",
    "          \n",
    "    num_train = X.shape[0]\n",
    "    iterations_per_epoch = max(num_train / batch_size, 1)\n",
    "    \n",
    "    batch_idxes = np.random.choice(num_train, batch_size, replace=True)\n",
    "    X_batch = X[batch_idxes, :]\n",
    "    y_batch = y[batch_idxes]\n",
    "    \n",
    "    # evaluate class scores, [N x K]\n",
    "    hidden_layer = np.maximum(0, np.dot(X_batch, W) + b) # note, ReLU activation\n",
    "    scores = np.dot(hidden_layer, W2) + b2\n",
    "\n",
    "    # compute the class probabilities\n",
    "    exp_scores = np.exp(scores)\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]\n",
    "\n",
    "    # compute the loss: average cross-entropy loss and regularization\n",
    "    corect_logprobs = -np.log(probs[range(batch_size),y_batch])\n",
    "    data_loss = np.sum(corect_logprobs)/batch_size\n",
    "    reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)\n",
    "    loss = data_loss + reg_loss\n",
    "    if i % 100 == 0:\n",
    "        print(\"iteration %d: loss %f\" % (i, loss))\n",
    "\n",
    "    # compute the gradient on scores\n",
    "    dscores = probs\n",
    "    dscores[range(batch_size),y_batch] -= 1\n",
    "    dscores /= batch_size\n",
    "\n",
    "    # backpropate the gradient to the parameters\n",
    "    # first backprop into parameters W2 and b2\n",
    "    dW2 = np.dot(hidden_layer.T, dscores)\n",
    "    db2 = np.sum(dscores, axis=0, keepdims=True)\n",
    "    # next backprop into hidden layer\n",
    "    dhidden = np.dot(dscores, W2.T)\n",
    "    # backprop the ReLU non-linearity\n",
    "    dhidden[hidden_layer <= 0] = 0\n",
    "    # finally into W,b\n",
    "    dW = np.dot(X_batch.T, dhidden)\n",
    "    db = np.sum(dhidden, axis=0, keepdims=True)\n",
    "\n",
    "    # add regularization gradient contribution\n",
    "    dW2 += reg * W2\n",
    "    dW += reg * W\n",
    "\n",
    "    # perform a parameter update\n",
    "    W += -step_size * dW\n",
    "    b += -step_size * db\n",
    "    W2 += -step_size * dW2\n",
    "    b2 += -step_size * db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "# evaluate training set accuracy\n",
    "hidden_layer = np.maximum(0, np.dot(X, W) + b)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print('training accuracy: %.2f' % (np.mean(predicted_class == y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "hidden_layer = np.maximum(0, np.dot(Xt, W) + b)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "print('test accuracy: %.2f' % (np.mean(predicted_class == yt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test some random digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEIAAAD8CAYAAADDlHLtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b3736d8898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size \n",
    "batch_idxes = np.random.choice(len(Xt), 10, replace=True)\n",
    "X_batch = Xt[batch_idxes, :]\n",
    "    \n",
    "pixels = X_batch # np.array(mnist.data[index], dtype='uint8')\n",
    "\n",
    "# Reshape the array into 28 x 28 array (2-dimensional array)\n",
    "pixels = pixels.reshape((280,28))\n",
    "\n",
    "# Plot\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test what the classifier classifies the above digits as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 8, 4, 5, 6, 4, 6, 7, 0], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer = np.maximum(0, np.dot(X_batch, W) + b)\n",
    "scores = np.dot(hidden_layer, W2) + b2\n",
    "predicted_class = np.argmax(scores, axis=1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Using Keras with Tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(y)\n",
    "test_labels = to_categorical(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 7s 115us/step - loss: 0.6495 - acc: 0.8262\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 109us/step - loss: 0.3669 - acc: 0.8977\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.3209 - acc: 0.9092\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 117us/step - loss: 0.2952 - acc: 0.9162\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.2761 - acc: 0.9223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b333ea4048>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(X, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 136us/step\n",
      "test_acc: 0.9268\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(Xt, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing optimizer to rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network2 = models.Sequential()\n",
    "network2.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "network2.add(layers.Dense(10, activation='softmax'))\n",
    "network2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.4530 - acc: 0.8754\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.1531 - acc: 0.9532\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.1118 - acc: 0.9653\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0896 - acc: 0.9720\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0755 - acc: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1989b041a58>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network2.fit(X, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 102us/step\n",
      "test_acc: 0.958\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network2.evaluate(Xt, test_labels)\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: keras also includes MNIST and in an easier to use format:\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28*28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28*28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
